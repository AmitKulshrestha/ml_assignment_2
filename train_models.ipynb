{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a91bac2a-b7dd-4356-b5ca-634413a3faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MACHINE LEARNING ASSIGNMENT 2 - MODEL TRAINING\n",
      "Dataset: Heart Disease UCI\n",
      "============================================================\n",
      "\n",
      "1. LOADING DATASET...\n",
      "\n",
      "Dataset Shape: (918, 12)\n",
      "Features: 11\n",
      "Instances: 918\n",
      "\n",
      "Target Distribution:\n",
      "HeartDisease\n",
      "1    508\n",
      "0    410\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n",
      "None\n",
      "\n",
      "2. PREPROCESSING DATA...\n",
      "Training set size: (734, 11)\n",
      "Test set size: (184, 11)\n",
      "\n",
      "3. TRAINING MODELS...\n",
      "\n",
      "Training Logistic Regression...\n",
      "  Accuracy: 0.8696\n",
      "  AUC: 0.8969\n",
      "  F1 Score: 0.8879\n",
      "  MCC: 0.7374\n",
      "\n",
      "Training Decision Tree...\n",
      "  Accuracy: 0.8098\n",
      "  AUC: 0.8582\n",
      "  F1 Score: 0.8293\n",
      "  MCC: 0.6146\n",
      "\n",
      "Training K-Nearest Neighbor...\n",
      "  Accuracy: 0.8913\n",
      "  AUC: 0.9192\n",
      "  F1 Score: 0.9029\n",
      "  MCC: 0.7797\n",
      "\n",
      "Training Naive Bayes...\n",
      "  Accuracy: 0.8913\n",
      "  AUC: 0.9280\n",
      "  F1 Score: 0.9029\n",
      "  MCC: 0.7797\n",
      "\n",
      "Training Random Forest...\n",
      "  Accuracy: 0.8750\n",
      "  AUC: 0.9235\n",
      "  F1 Score: 0.8889\n",
      "  MCC: 0.7465\n",
      "\n",
      "Training XGBoost...\n",
      "  Accuracy: 0.8696\n",
      "  AUC: 0.9230\n",
      "  F1 Score: 0.8800\n",
      "  MCC: 0.7380\n",
      "\n",
      "============================================================\n",
      "4. MODEL COMPARISON TABLE\n",
      "============================================================\n",
      "                    Accuracy     AUC Precision  Recall      F1     MCC\n",
      "Logistic Regression   0.8696  0.8969    0.8482  0.9314  0.8879  0.7374\n",
      "Decision Tree         0.8098  0.8582    0.8252  0.8333  0.8293  0.6146\n",
      "K-Nearest Neighbor    0.8913  0.9192    0.8942  0.9118  0.9029  0.7797\n",
      "Naive Bayes           0.8913   0.928    0.8942  0.9118  0.9029  0.7797\n",
      "Random Forest          0.875  0.9235    0.8762   0.902  0.8889  0.7465\n",
      "XGBoost               0.8696   0.923     0.898  0.8627    0.88   0.738\n",
      "\n",
      "Results saved to models/model_comparison.csv\n",
      "\n",
      "============================================================\n",
      "5. CROSS-VALIDATION SCORES (5-Fold)\n",
      "============================================================\n",
      "Logistic Regression       CV Accuracy: 0.8473 (+/- 0.0763)\n",
      "Decision Tree             CV Accuracy: 0.8174 (+/- 0.0515)\n",
      "K-Nearest Neighbor        CV Accuracy: 0.8447 (+/- 0.0322)\n",
      "Naive Bayes               CV Accuracy: 0.8473 (+/- 0.0770)\n",
      "Random Forest             CV Accuracy: 0.8542 (+/- 0.0299)\n",
      "XGBoost                   CV Accuracy: 0.8256 (+/- 0.0412)\n",
      "\n",
      "============================================================\n",
      "MODEL TRAINING COMPLETED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, \n",
    "                           recall_score, f1_score, matthews_corrcoef, \n",
    "                           confusion_matrix, classification_report)\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "import kagglehub\n",
    "import shutil\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MACHINE LEARNING ASSIGNMENT 2 - MODEL TRAINING\")\n",
    "print(\"Dataset: Heart Disease UCI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Step 1: Load and prepare the dataset\n",
    "print(\"\\n1. LOADING DATASET...\")\n",
    "df = pd.read_csv(\"I:\\\\BITS MTech\\\\Semester-1\\\\3-Machine Learning\\\\Assignment-2\\\\dataset\\\\heart.csv\")\n",
    "\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "print(f\"Features: {df.shape[1]-1}\")\n",
    "print(f\"Instances: {df.shape[0]}\")\n",
    "print(f\"\\nTarget Distribution:\")\n",
    "print(df['HeartDisease'].value_counts())\n",
    "print(f\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "print(\"\\n2. PREPROCESSING DATA...\")\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']\n",
    "\n",
    "# Encode categorical variables if any\n",
    "le = LabelEncoder()\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features for certain algorithms\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Save scaler for later use\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "\n",
    "# Step 3: Define models\n",
    "print(\"\\n3. TRAINING MODELS...\")\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),\n",
    "    'K-Nearest Neighbor': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Use scaled data for Logistic Regression and KNN\n",
    "    if name in ['Logistic Regression', 'K-Nearest Neighbor']:\n",
    "        X_train_use = X_train_scaled\n",
    "        X_test_use = X_test_scaled\n",
    "    else:\n",
    "        X_train_use = X_train\n",
    "        X_test_use = X_test\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_use, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_use)\n",
    "    \n",
    "    # For AUC score\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test_use)[:, 1]\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        auc_score = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'AUC': round(auc_score, 4),\n",
    "        'Precision': round(precision, 4),\n",
    "        'Recall': round(recall, 4),\n",
    "        'F1': round(f1, 4),\n",
    "        'MCC': round(mcc, 4),\n",
    "        'Model': model,\n",
    "        'Predictions': y_pred,\n",
    "        'True': y_test.values\n",
    "    }\n",
    "    \n",
    "    # Save model\n",
    "    filename = name.lower().replace(' ', '_').replace('-', '_')\n",
    "    joblib.dump(model, f'models/{filename}.pkl')\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  AUC: {auc_score:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  MCC: {mcc:.4f}\")\n",
    "\n",
    "# Step 4: Display results table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4. MODEL COMPARISON TABLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "comparison_table = comparison_df[['Accuracy', 'AUC', 'Precision', 'Recall', 'F1', 'MCC']]\n",
    "print(comparison_table.to_string())\n",
    "\n",
    "# Save results to CSV\n",
    "comparison_table.to_csv('models/model_comparison.csv')\n",
    "print(\"\\nResults saved to models/model_comparison.csv\")\n",
    "\n",
    "# Step 5: Cross-validation scores\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5. CROSS-VALIDATION SCORES (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name in ['Logistic Regression', 'K-Nearest Neighbor']:\n",
    "        X_use = X_train_scaled\n",
    "    else:\n",
    "        X_use = X_train\n",
    "    \n",
    "    cv_scores = cross_val_score(model, X_use, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"{name:25} CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
